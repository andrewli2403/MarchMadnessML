{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#enter team statistics for predictions\n",
    "teamdatas = input(\"Enter team statistics.\")\n",
    "print(teamdatas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in processed data from CollegeBasketballPredictor.ipynb\n",
    "def load_marchmadness():\n",
    "    #features from training, test, validation sets\n",
    "    featurestrainingData = torch.load('featurestraining_pytorch.pt')\n",
    "    featurestestData = torch.load('featurestest_pytorch.pt')\n",
    "    featuresvalidationData = torch.load('featuresvalidation_pytorch.pt')\n",
    "    \n",
    "    #labels from training, test, validation sets\n",
    "    labelstrainingData = torch.load('labelstraining_pytorch.pt')\n",
    "    labelstestData = torch.load('labelstest_pytorch.pt')\n",
    "    labelsvalidationData = torch.load('labelsvalidation_pytorch.pt')\n",
    "    \n",
    "    return featurestrainingData, labelstrainingData, featurestestData, labelstestData, featuresvalidationData, labelsvalidationData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_dim, output_dim):\n",
    "    # We don't need the softmax layer here since CrossEntropyLoss already\n",
    "    # uses it internally.\n",
    "    model = torch.nn.Sequential()\n",
    "    model.add_module(\"linear\",\n",
    "                     torch.nn.Linear(input_dim, output_dim, bias=False))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss, optimizer, x, y):\n",
    "    # Reset gradient\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward\n",
    "    fx = model.forward(x)\n",
    "    output = loss.forward(fx, y)\n",
    "\n",
    "    # Backward\n",
    "    output.backward()\n",
    "\n",
    "    # Update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    return output.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, x):\n",
    "    output = model.forward(x)\n",
    "    return output.data.numpy().argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_list = [0.0001, 0.001, 0.01, 0.1, 1.0]\n",
    "result_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    torch.manual_seed(42)\n",
    "    #X is data Y is label\n",
    "    trX, trY, teX, teY, valX, valY = load_marchmadness()\n",
    "    \n",
    "    n_examples, n_features = list(trX.size())[0], list(trX.size())[1]\n",
    "    n_classes = 2\n",
    "    model = build_model(n_features, n_classes)\n",
    "    loss = torch.nn.CrossEntropyLoss(reduction='elementwise_mean')\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    batch_size = 100\n",
    "\n",
    "    for i in range(100):\n",
    "        cost = 0.\n",
    "        num_batches = n_examples // batch_size\n",
    "        for k in range(num_batches):\n",
    "            start, end = k * batch_size, (k + 1) * batch_size\n",
    "            cost += train(model, loss, optimizer,\n",
    "                          trX[start:end], trY[start:end])\n",
    "        predY = predict(model, teX)\n",
    "        print(\"Epoch %d, cost = %f, acc = %.2f%%\"\n",
    "              #.cpu().numpy() turns it back into a numpy array\n",
    "              % (i + 1, cost / num_batches, 100. * np.mean(predY == teY.cpu().numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
